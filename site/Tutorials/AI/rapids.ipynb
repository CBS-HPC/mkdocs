{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "146078eb",
   "metadata": {},
   "source": [
    "# RAPIDS-cuML: Train your Scikit-learn models on AAU GPUs\n",
    "\n",
    "This tutorial show how to deploy [RAPIDS-cuML-GPU Machine Learning Algorithms](https://github.com/rapidsai/cuml) to efficiently train your scikit-learn models on the AAU GPUs avalaible through UCloud. \n",
    "\n",
    "\"cuML is a suite of libraries that implement machine learning algorithms and mathematical primitives functions. cuML enables data scientists, researchers, and software engineers to run traditional tabular ML tasks on GPUs without going into the details of CUDA programming. For large datasets, these GPU-based implementations can complete 10-50x faster than their CPU equivalents. For details on performance, see the [cuML Benchmarks Notebook](https://github.com/rapidsai/cuml/tree/branch-23.04/notebooks/tools).\"\n",
    "\n",
    " **In most cases, cuML's Python API matches the API from scikit-learn. which will make it easy to navigate from scikit-learn to RAPIDS-cuML**\n",
    "\n",
    "A table of the supported algoritmns can be found [here](https://github.com/rapidsai/cuml#supported-algorithms). \n",
    "\n",
    "This tutorial will use a random forrest which can be found on the [cuML notebook examples](https://github.com/rapidsai/cuml/tree/branch-23.04/notebooks)\n",
    "\n",
    "The following python script is needed to replicate this tutorial: \n",
    "\n",
    "- [multigpu_rapids.py](https://github.com/CBS-HPC/Tutorials/tree/main/AI/multigpu_rapids.py) (Can be used as template)\n",
    "\n",
    "\n",
    "Prerequisite reading:\n",
    "\n",
    "- [How to Generate SSH key](/Tutorials/VMs/shh/)\n",
    "\n",
    "- [Access VM using SSH](/Tutorials/VMs/connectVM/)\n",
    "\n",
    "- [Using Conda for easy workflow deployment on AAU GPU VMs](/Tutorials/VMs/condaVM/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc96308e",
   "metadata": {},
   "source": [
    "### Update VM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893ef50e",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sudo apt update\n",
    "sudo apt upgrade -y \n",
    "sudo apt install nvidia-driver-525 nvidia-utils-525 -y  # Or newer version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0a4fce",
   "metadata": {},
   "source": [
    "### Activate Conda\n",
    "\n",
    "This can be done by either installing a conda from scratch or by deploying er prior installation. Please see  [\"Using Conda for easy workflow deployment on AAU GPU VMs\"](/Tutorials/VMs/condaVM/) for information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de54fa2",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Download and install miniconda (If needed)\n",
    "curl -s -L -o miniconda_installer.sh https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh \n",
    "bash miniconda_installer.sh -b -f -p miniconda3\n",
    "\n",
    "# Set conda to path\n",
    "export PATH=/home/ucloud/miniconda3/bin:$PATH # Set conda to path\n",
    "\n",
    "# initialize conda\n",
    "conda init && bash -i\n",
    "\n",
    "# Reboot VM\n",
    "sudo reboot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde7003c",
   "metadata": {},
   "source": [
    "### Re-connect to VM using SSH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc34140d",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ssh ucloud@IP_address_from_the_red_mark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618a940f",
   "metadata": {},
   "source": [
    "### Check nvidia driver Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aa33cc",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "nvidia-smi\n",
    "\n",
    "# Expected Output\n",
    "Mon Aug  7 09:38:25 2023\n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 470.199.02   Driver Version: 470.199.02   CUDA Version: 11.4     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n",
    "| N/A   70C    P0    31W /  70W |      0MiB / 15109MiB |      7%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "\n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "|  No running processes found                                                 |\n",
    "+-----------------------------------------------------------------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48acbfb3",
   "metadata": {},
   "source": [
    "### Create or re-load a RAPIDS Conda environment\n",
    "\n",
    "look for latest RAPIDS installation at https://docs.rapids.ai/install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129f32b6",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Create pytorch conda environment if non-exist on the Conda installation\n",
    "conda deactivate\n",
    "conda create --solver=libmamba -n rapids -c rapidsai -c conda-forge -c nvidia  \\\n",
    "    rapids=23.08 python=3.10 cuda-version=11.8\n",
    "\n",
    "\n",
    "# Set pre-installed conda libraries to path (including cudatoolkit=11.2 cudnn=8.1.0 )\n",
    "export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$CONDA_PREFIX/lib/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13010f19",
   "metadata": {},
   "source": [
    "\n",
    "### Transfer Files and Folders (SSH-Copy) to VM\n",
    "Open a second terminal (1st terminal is connected to the VM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de36343a",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "scp -r \"C:\\path\\pytorch_folder\" ucloud@IP_address_from_the_red_mark:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90899ed3",
   "metadata": {},
   "source": [
    "### Run a Random Forrest training on multiple GPUs: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2da8dd",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python multigpu_rapids.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a85152",
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import cudf\n",
    "import cuml\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from cuml import datasets\n",
    "from cuml.metrics import accuracy_score\n",
    "from cuml.dask.common import utils as dask_utils\n",
    "from dask.distributed import Client, wait\n",
    "from dask_cuda import LocalCUDACluster\n",
    "import dask_cudf\n",
    "\n",
    "from cuml.dask.ensemble import RandomForestClassifier as cumlDaskRF\n",
    "from sklearn.ensemble import RandomForestClassifier as sklRF\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ### Start Dask cluster\n",
    "    # This will use all GPUs on the local host by default\n",
    "    cluster = LocalCUDACluster(n_workers=2)\n",
    "    #cluster = LocalCUDACluster(threads_per_worker=1)\n",
    "    c = Client(cluster)\n",
    "\n",
    "    # Query the client for all connected workers\n",
    "    workers = c.has_what().keys()\n",
    "    n_workers = len(workers)\n",
    "    n_streams = 8 # Performance optimization\n",
    "\n",
    "    ### Define Parameters\n",
    "    # Data parameters\n",
    "    train_size = 500000\n",
    "    test_size = 1000\n",
    "    n_samples = train_size + test_size\n",
    "    n_features = 20\n",
    "\n",
    "    # Random Forest building parameters\n",
    "    max_depth = 12\n",
    "    n_bins = 16\n",
    "    n_trees = 5000\n",
    "\n",
    "    ### Generate Data on host\n",
    "    X, y = datasets.make_classification(n_samples=n_samples, n_features=n_features,\n",
    "                                    n_clusters_per_class=1, n_informative=int(n_features / 3),\n",
    "                                    random_state=123, n_classes=5)\n",
    "    X = X.astype(np.float32)\n",
    "    y = y.astype(np.int32)\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=test_size)\n",
    "\n",
    "    ### Distribute data to worker GPUs\n",
    "    n_partitions = n_workers\n",
    "\n",
    "    def distribute(X, y):\n",
    "        # First convert to cudf (with real data, you would likely load in cuDF format to start)\n",
    "        X_cudf = cudf.DataFrame(X)\n",
    "        y_cudf = cudf.Series(y)\n",
    "\n",
    "        # Partition with Dask\n",
    "        # In this case, each worker will train on 1/n_partitions fraction of the data\n",
    "        X_dask = dask_cudf.from_cudf(X_cudf, npartitions=n_partitions)\n",
    "        y_dask = dask_cudf.from_cudf(y_cudf, npartitions=n_partitions)\n",
    "\n",
    "        # Persist to cache the data in active memory\n",
    "        X_dask, y_dask = \\\n",
    "        dask_utils.persist_across_workers(c, [X_dask, y_dask], workers=workers)\n",
    "        \n",
    "        return X_dask, y_dask\n",
    "\n",
    "    X_train_dask, y_train_dask = distribute(X_train, y_train)\n",
    "    X_test_dask, y_test_dask = distribute(X_test, y_test)\n",
    "\n",
    "    ### Build a scikit-learn model (single node)\n",
    "    # Use all available CPU cores\n",
    "    #skl_model = sklRF(max_depth=max_depth, n_estimators=n_trees, n_jobs=-1)\n",
    "    #skl_model.fit(X_train.get(), y_train.get())\n",
    "    #finish_time = time.perf_counter()\n",
    "\n",
    "    ### Predict\n",
    "    #skl_y_pred = skl_model.predict(X_test.get())\n",
    "    #print(\"SKLearn accuracy:  \", accuracy_score(y_test, skl_y_pred))\n",
    "\n",
    "    ### Train the distributed cuML model\n",
    "    cuml_model = cumlDaskRF(max_depth=max_depth, n_estimators=n_trees, n_bins=n_bins, n_streams=n_streams)\n",
    "    cuml_model.fit(X_train_dask, y_train_dask)\n",
    "    wait(cuml_model.rfs) # Allow asynchronous training tasks to finishfinish_time = time.perf_counter()\n",
    "    finish_time = time.perf_counter()\n",
    "\n",
    "    ### Predict\n",
    "    cuml_y_pred = cuml_model.predict(X_test_dask).compute().to_numpy()\n",
    "    print(\"CuML accuracy:     \", accuracy_score(y_test, cuml_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6088a5ff",
   "metadata": {},
   "source": [
    "### Track the GPU usage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff65ba20",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "nvidia-smi -l 5 # Will update every 5 seconds\n",
    "\n",
    "# Expected Output\n",
    "Mon Aug  7 09:38:25 2023\n",
    "+-----------------------------------------------------------------------------+\n",
    "| Processes:                                                                  |\n",
    "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
    "|        ID   ID                                                   Usage      |\n",
    "|=============================================================================|\n",
    "|    0   N/A  N/A      1011      G   /usr/lib/xorg/Xorg                  4MiB |\n",
    "|    0   N/A  N/A      2312      C   python                           1324MiB |\n",
    "|    0   N/A  N/A      2381      C   ...a3/envs/rapids/bin/python     1042MiB |\n",
    "|    1   N/A  N/A      1011      G   /usr/lib/xorg/Xorg                  4MiB |\n",
    "|    1   N/A  N/A      2383      C   ...a3/envs/rapids/bin/python     1042MiB |\n",
    "+-----------------------------------------------------------------------------+\n",
    "Tue Aug 29 11:04:31 2023\n",
    "+-----------------------------------------------------------------------------+\n",
    "| NVIDIA-SMI 525.125.06   Driver Version: 525.125.06   CUDA Version: 12.0     |\n",
    "|-------------------------------+----------------------+----------------------+\n",
    "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
    "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
    "|                               |                      |               MIG M. |\n",
    "|===============================+======================+======================|\n",
    "|   0  Tesla T4            Off  | 00000000:00:05.0 Off |                    0 |\n",
    "| N/A   38C    P0    49W /  70W |   2389MiB / 15360MiB |     93%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+\n",
    "|   1  Tesla T4            Off  | 00000000:00:06.0 Off |                    0 |\n",
    "| N/A   36C    P0    53W /  70W |   1067MiB / 15360MiB |     93%      Default |\n",
    "|                               |                      |                  N/A |\n",
    "+-------------------------------+----------------------+----------------------+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9f25d",
   "metadata": {},
   "source": [
    "### Transfer Results and Conda enviroment local machine (SSH-Copy)\n",
    "Open a second terminal (1st terminal is connected to the VM):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eacf695",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "scp -r ucloud@IP_address_from_the_red_mark:/home/ucloud/folder \"C:\\path-to-folder\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
