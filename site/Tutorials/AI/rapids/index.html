
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
      
      <link rel="icon" href="../../../images/CBS_logo2.png">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.15">
    
    
      
        <title>RAPIDS-cuML: Train your Scikit-learn models on AAU GPUs - HPC & Data Science Support</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.26e3688c.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.ecc896b0.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="blue">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#rapids-cuml-train-your-scikit-learn-models-on-aau-gpus" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="https://example.com" title="HPC &amp; Data Science Support" class="md-header__button md-logo" aria-label="HPC & Data Science Support" data-md-component="logo">
      
  <img src="../../../images/CBS_logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            HPC & Data Science Support
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              RAPIDS-cuML: Train your Scikit-learn models on AAU GPUs
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
          
            
            
            
            <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="blue"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
            
              <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 6H7c-3.31 0-6 2.69-6 6s2.69 6 6 6h10c3.31 0 6-2.69 6-6s-2.69-6-6-6zm0 10H7c-2.21 0-4-1.79-4-4s1.79-4 4-4h10c2.21 0 4 1.79 4 4s-1.79 4-4 4zM7 9c-1.66 0-3 1.34-3 3s1.34 3 3 3 3-1.34 3-3-1.34-3-3-3z"/></svg>
              </label>
            
          
            
            
            
            <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="blue"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
            
              <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 7H7a5 5 0 0 0-5 5 5 5 0 0 0 5 5h10a5 5 0 0 0 5-5 5 5 0 0 0-5-5m0 8a3 3 0 0 1-3-3 3 3 0 0 1 3-3 3 3 0 0 1 3 3 3 3 0 0 1-3 3Z"/></svg>
              </label>
            
          
        </form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/CBS-HPC/CBS-HPC.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    CBS-HPC/CBS-HPC.github.io
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../../.." class="md-tabs__link">
      Home
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../../news/" class="md-tabs__link">
      News
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../../events/" class="md-tabs__link">
      Events
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../../hpc/" class="md-tabs__link">
      HPC Facilites
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../../getresources/" class="md-tabs__link">
      Get Resources
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../../tut_docs/" class="md-tabs__link">
      Tutorials & Documentation
    </a>
  </li>

      
        
  
  


  <li class="md-tabs__item">
    <a href="../../../contact/" class="md-tabs__link">
      Contact
    </a>
  </li>

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="https://example.com" title="HPC &amp; Data Science Support" class="md-nav__button md-logo" aria-label="HPC & Data Science Support" data-md-component="logo">
      
  <img src="../../../images/CBS_logo.png" alt="logo">

    </a>
    HPC & Data Science Support
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/CBS-HPC/CBS-HPC.github.io" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    CBS-HPC/CBS-HPC.github.io
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../news/" class="md-nav__link">
        News
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../events/" class="md-nav__link">
        Events
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../hpc/" class="md-nav__link">
        HPC Facilites
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../getresources/" class="md-nav__link">
        Get Resources
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../tut_docs/" class="md-nav__link">
        Tutorials & Documentation
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../contact/" class="md-nav__link">
        Contact
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#update-vm" class="md-nav__link">
    Update VM
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#activate-conda" class="md-nav__link">
    Activate Conda
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#re-connect-to-vm-using-ssh" class="md-nav__link">
    Re-connect to VM using SSH
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#check-nvidia-driver-configuration" class="md-nav__link">
    Check nvidia driver Configuration
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#create-or-re-load-a-rapids-conda-environment" class="md-nav__link">
    Create or re-load a RAPIDS Conda environment
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transfer-files-and-folders-ssh-copy-to-vm" class="md-nav__link">
    Transfer Files and Folders (SSH-Copy) to VM
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#run-a-random-forrest-training-on-multiple-gpus" class="md-nav__link">
    Run a Random Forrest training on multiple GPUs:
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#track-the-gpu-usage" class="md-nav__link">
    Track the GPU usage
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#transfer-results-and-conda-enviroment-local-machine-ssh-copy" class="md-nav__link">
    Transfer Results and Conda enviroment local machine (SSH-Copy)
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


<h1 id="rapids-cuml-train-your-scikit-learn-models-on-aau-gpus">RAPIDS-cuML: Train your Scikit-learn models on AAU GPUs<a class="headerlink" href="#rapids-cuml-train-your-scikit-learn-models-on-aau-gpus" title="Permanent link">&para;</a></h1>
<p>This tutorial show how to deploy <a href="https://github.com/rapidsai/cuml">RAPIDS-cuML-GPU Machine Learning Algorithms</a> to efficiently train your scikit-learn models on the AAU GPUs avalaible through UCloud. </p>
<p>"cuML is a suite of libraries that implement machine learning algorithms and mathematical primitives functions. cuML enables data scientists, researchers, and software engineers to run traditional tabular ML tasks on GPUs without going into the details of CUDA programming. For large datasets, these GPU-based implementations can complete 10-50x faster than their CPU equivalents. For details on performance, see the <a href="https://github.com/rapidsai/cuml/tree/branch-23.04/notebooks/tools">cuML Benchmarks Notebook</a>."</p>
<p><strong>In most cases, cuML's Python API matches the API from scikit-learn. which will make it easy to navigate from scikit-learn to RAPIDS-cuML</strong></p>
<p>A table of the supported algoritmns can be found <a href="https://github.com/rapidsai/cuml#supported-algorithms">here</a>. </p>
<p>This tutorial will use a random forrest which can be found on the <a href="https://github.com/rapidsai/cuml/tree/branch-23.04/notebooks">cuML notebook examples</a></p>
<p>The following python script is needed to replicate this tutorial: </p>
<ul>
<li><a href="https://github.com/CBS-HPC/Tutorials/tree/main/AI/multigpu_rapids.py">multigpu_rapids.py</a> (Can be used as template)</li>
</ul>
<p>Prerequisite reading:</p>
<ul>
<li>
<p><a href="/Tutorials/VMs/shh/">How to Generate SSH key</a></p>
</li>
<li>
<p><a href="/Tutorials/VMs/connectVM/">Access VM using SSH</a></p>
</li>
<li>
<p><a href="/Tutorials/VMs/condaVM/">Using Conda for easy workflow deployment on AAU GPU VMs</a></p>
</li>
</ul>
<h3 id="update-vm">Update VM<a class="headerlink" href="#update-vm" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">sudo</span><span class="w"> </span><span class="n">apt</span><span class="w"> </span><span class="n">update</span>
<span class="n">sudo</span><span class="w"> </span><span class="n">apt</span><span class="w"> </span><span class="n">upgrade</span><span class="w"> </span><span class="o">-</span><span class="n">y</span><span class="w"> </span>
<span class="n">sudo</span><span class="w"> </span><span class="n">apt</span><span class="w"> </span><span class="n">install</span><span class="w"> </span><span class="n">nvidia</span><span class="o">-</span><span class="n">driver</span><span class="m">-525</span><span class="w"> </span><span class="n">nvidia</span><span class="o">-</span><span class="n">utils</span><span class="m">-525</span><span class="w"> </span><span class="o">-</span><span class="n">y</span><span class="w">  </span><span class="c1"># Or newer version</span>
</code></pre></div>
<h3 id="activate-conda">Activate Conda<a class="headerlink" href="#activate-conda" title="Permanent link">&para;</a></h3>
<p>This can be done by either installing a conda from scratch or by deploying er prior installation. Please see  <a href="/Tutorials/VMs/condaVM/">"Using Conda for easy workflow deployment on AAU GPU VMs"</a> for information.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Download and install miniconda (If needed)</span>
<span class="n">curl</span><span class="w"> </span><span class="o">-</span><span class="n">s</span><span class="w"> </span><span class="o">-</span><span class="n">L</span><span class="w"> </span><span class="o">-</span><span class="n">o</span><span class="w"> </span><span class="n">miniconda_installer.sh</span><span class="w"> </span><span class="n">https</span><span class="o">://</span><span class="n">repo.anaconda.com</span><span class="o">/</span><span class="n">miniconda</span><span class="o">/</span><span class="n">Miniconda3</span><span class="o">-</span><span class="n">latest</span><span class="o">-</span><span class="n">Linux</span><span class="o">-</span><span class="n">x86_64.sh</span><span class="w"> </span>
<span class="n">bash</span><span class="w"> </span><span class="n">miniconda_installer.sh</span><span class="w"> </span><span class="o">-</span><span class="n">b</span><span class="w"> </span><span class="o">-</span><span class="n">f</span><span class="w"> </span><span class="o">-</span><span class="n">p</span><span class="w"> </span><span class="n">miniconda3</span>

<span class="c1"># Set conda to path</span>
<span class="n">export</span><span class="w"> </span><span class="n">PATH</span><span class="o">=/</span><span class="n">home</span><span class="o">/</span><span class="n">ucloud</span><span class="o">/</span><span class="n">miniconda3</span><span class="o">/</span><span class="n">bin</span><span class="o">:$</span><span class="n">PATH</span><span class="w"> </span><span class="c1"># Set conda to path</span>

<span class="c1"># initialize conda</span>
<span class="n">conda</span><span class="w"> </span><span class="n">init</span><span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="n">bash</span><span class="w"> </span><span class="o">-</span><span class="n">i</span>

<span class="c1"># Reboot VM</span>
<span class="n">sudo</span><span class="w"> </span><span class="n">reboot</span>
</code></pre></div>
<h3 id="re-connect-to-vm-using-ssh">Re-connect to VM using SSH<a class="headerlink" href="#re-connect-to-vm-using-ssh" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">ssh</span><span class="w"> </span><span class="n">ucloud</span><span class="o">@</span><span class="n">IP_address_from_the_red_mark</span>
</code></pre></div>
<h3 id="check-nvidia-driver-configuration">Check nvidia driver Configuration<a class="headerlink" href="#check-nvidia-driver-configuration" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">nvidia</span><span class="o">-</span><span class="n">smi</span>

<span class="c1"># Expected Output</span>
<span class="n">Mon</span><span class="w"> </span><span class="n">Aug</span><span class="w">  </span><span class="m">7</span><span class="w"> </span><span class="m">09</span><span class="o">:</span><span class="m">38</span><span class="o">:</span><span class="m">25</span><span class="w"> </span><span class="m">2023</span>
<span class="o">+-----------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="w"> </span><span class="n">NVIDIA</span><span class="o">-</span><span class="n">SMI</span><span class="w"> </span><span class="m">470.199</span><span class="n">.</span><span class="m">02</span><span class="w">   </span><span class="n">Driver</span><span class="w"> </span><span class="n">Version</span><span class="o">:</span><span class="w"> </span><span class="m">470.199</span><span class="n">.</span><span class="m">02</span><span class="w">   </span><span class="n">CUDA</span><span class="w"> </span><span class="n">Version</span><span class="o">:</span><span class="w"> </span><span class="m">11.4</span><span class="w">     </span><span class="o">|</span>
<span class="o">|-------------------------------+----------------------+----------------------+</span>
<span class="o">|</span><span class="w"> </span><span class="n">GPU</span><span class="w">  </span><span class="n">Name</span><span class="w">        </span><span class="n">Persistence</span><span class="o">-</span><span class="n">M</span><span class="o">|</span><span class="w"> </span><span class="n">Bus</span><span class="o">-</span><span class="n">Id</span><span class="w">        </span><span class="n">Disp.A</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Volatile</span><span class="w"> </span><span class="n">Uncorr.</span><span class="w"> </span><span class="n">ECC</span><span class="w"> </span><span class="o">|</span>
<span class="o">|</span><span class="w"> </span><span class="n">Fan</span><span class="w">  </span><span class="n">Temp</span><span class="w">  </span><span class="n">Perf</span><span class="w">  </span><span class="n">Pwr</span><span class="o">:</span><span class="n">Usage</span><span class="o">/</span><span class="n">Cap</span><span class="o">|</span><span class="w">         </span><span class="n">Memory</span><span class="o">-</span><span class="n">Usage</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">GPU</span><span class="o">-</span><span class="n">Util</span><span class="w">  </span><span class="n">Compute</span><span class="w"> </span><span class="n">M.</span><span class="w"> </span><span class="o">|</span>
<span class="o">|</span><span class="w">                               </span><span class="o">|</span><span class="w">                      </span><span class="o">|</span><span class="w">               </span><span class="n">MIG</span><span class="w"> </span><span class="n">M.</span><span class="w"> </span><span class="o">|</span>
<span class="o">|===============================+======================+======================|</span>
<span class="o">|</span><span class="w">   </span><span class="m">0</span><span class="w">  </span><span class="n">Tesla</span><span class="w"> </span><span class="n">T4</span><span class="w">            </span><span class="n">Off</span><span class="w">  </span><span class="o">|</span><span class="w"> </span><span class="m">00000000</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">05.0</span><span class="w"> </span><span class="n">Off</span><span class="w"> </span><span class="o">|</span><span class="w">                    </span><span class="m">0</span><span class="w"> </span><span class="o">|</span>
<span class="o">|</span><span class="w"> </span><span class="n">N</span><span class="o">/</span><span class="n">A</span><span class="w">   </span><span class="m">70</span><span class="n">C</span><span class="w">    </span><span class="n">P0</span><span class="w">    </span><span class="m">31</span><span class="n">W</span><span class="w"> </span><span class="o">/</span><span class="w">  </span><span class="m">70</span><span class="n">W</span><span class="w"> </span><span class="o">|</span><span class="w">      </span><span class="m">0</span><span class="n">MiB</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="m">15109</span><span class="n">MiB</span><span class="w"> </span><span class="o">|</span><span class="w">      </span><span class="m">7</span>%<span class="w">      </span><span class="n">Default</span><span class="w"> </span><span class="o">|</span>
<span class="o">|</span><span class="w">                               </span><span class="o">|</span><span class="w">                      </span><span class="o">|</span><span class="w">                  </span><span class="n">N</span><span class="o">/</span><span class="n">A</span><span class="w"> </span><span class="o">|</span>
<span class="o">+-------------------------------+----------------------+----------------------+</span>

<span class="o">+-----------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="w"> </span><span class="n">Processes</span><span class="o">:</span><span class="w">                                                                  </span><span class="o">|</span>
<span class="o">|</span><span class="w">  </span><span class="n">GPU</span><span class="w">   </span><span class="n">GI</span><span class="w">   </span><span class="n">CI</span><span class="w">        </span><span class="n">PID</span><span class="w">   </span><span class="n">Type</span><span class="w">   </span><span class="n">Process</span><span class="w"> </span><span class="n">name</span><span class="w">                  </span><span class="n">GPU</span><span class="w"> </span><span class="n">Memory</span><span class="w"> </span><span class="o">|</span>
<span class="o">|</span><span class="w">        </span><span class="n">ID</span><span class="w">   </span><span class="n">ID</span><span class="w">                                                   </span><span class="n">Usage</span><span class="w">      </span><span class="o">|</span>
<span class="o">|=============================================================================|</span>
<span class="o">|</span><span class="w">  </span><span class="n">No</span><span class="w"> </span><span class="n">running</span><span class="w"> </span><span class="n">processes</span><span class="w"> </span><span class="n">found</span><span class="w">                                                 </span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------+</span>
</code></pre></div>
<h3 id="create-or-re-load-a-rapids-conda-environment">Create or re-load a RAPIDS Conda environment<a class="headerlink" href="#create-or-re-load-a-rapids-conda-environment" title="Permanent link">&para;</a></h3>
<p>look for latest RAPIDS installation at https://docs.rapids.ai/install</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Create pytorch conda environment if non-exist on the Conda installation</span>
<span class="n">conda</span><span class="w"> </span><span class="n">deactivate</span>
<span class="n">conda</span><span class="w"> </span><span class="n">create</span><span class="w"> </span><span class="o">--</span><span class="n">solver</span><span class="o">=</span><span class="n">libmamba</span><span class="w"> </span><span class="o">-</span><span class="n">n</span><span class="w"> </span><span class="n">rapids</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="n">rapidsai</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="n">conda</span><span class="o">-</span><span class="n">forge</span><span class="w"> </span><span class="o">-</span><span class="n">c</span><span class="w"> </span><span class="n">nvidia</span><span class="w">  </span>\
<span class="w">    </span><span class="n">rapids</span><span class="o">=</span><span class="m">23.08</span><span class="w"> </span><span class="n">python</span><span class="o">=</span><span class="m">3.10</span><span class="w"> </span><span class="n">cuda</span><span class="o">-</span><span class="n">version</span><span class="o">=</span><span class="m">11.8</span>


<span class="c1"># Set pre-installed conda libraries to path (including cudatoolkit=11.2 cudnn=8.1.0 )</span>
<span class="n">export</span><span class="w"> </span><span class="n">LD_LIBRARY_PATH</span><span class="o">=$</span><span class="n">LD_LIBRARY_PATH</span><span class="o">:$</span><span class="n">CONDA_PREFIX</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span>
</code></pre></div>
<h3 id="transfer-files-and-folders-ssh-copy-to-vm">Transfer Files and Folders (SSH-Copy) to VM<a class="headerlink" href="#transfer-files-and-folders-ssh-copy-to-vm" title="Permanent link">&para;</a></h3>
<p>Open a second terminal (1st terminal is connected to the VM):</p>
<div class="highlight"><pre><span></span><code><span class="n">scp</span><span class="w"> </span><span class="o">-</span><span class="n">r</span><span class="w"> </span><span class="s">&quot;C:\path\pytorch_folder&quot;</span><span class="w"> </span><span class="n">ucloud</span><span class="o">@</span><span class="n">IP_address_from_the_red_mark</span><span class="o">:</span>
</code></pre></div>
<h3 id="run-a-random-forrest-training-on-multiple-gpus">Run a Random Forrest training on multiple GPUs:<a class="headerlink" href="#run-a-random-forrest-training-on-multiple-gpus" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">python</span><span class="w"> </span><span class="n">multigpu_rapids.py</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">import</span><span class="w"> </span><span class="n">numpy</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">np</span>
<span class="n">import</span><span class="w"> </span><span class="n">sklearn</span>
<span class="n">import</span><span class="w"> </span><span class="n">time</span>

<span class="n">import</span><span class="w"> </span><span class="n">pandas</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">pd</span>
<span class="n">import</span><span class="w"> </span><span class="n">cudf</span>
<span class="n">import</span><span class="w"> </span><span class="n">cuml</span>

<span class="n">from</span><span class="w"> </span><span class="n">sklearn</span><span class="w"> </span><span class="n">import</span><span class="w"> </span><span class="n">model_selection</span>

<span class="n">from</span><span class="w"> </span><span class="n">cuml</span><span class="w"> </span><span class="n">import</span><span class="w"> </span><span class="n">datasets</span>
<span class="n">from</span><span class="w"> </span><span class="n">cuml.metrics</span><span class="w"> </span><span class="n">import</span><span class="w"> </span><span class="n">accuracy_score</span>
<span class="n">from</span><span class="w"> </span><span class="n">cuml.dask.common</span><span class="w"> </span><span class="n">import</span><span class="w"> </span><span class="n">utils</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">dask_utils</span>
<span class="n">from</span><span class="w"> </span><span class="n">dask.distributed</span><span class="w"> </span><span class="n">import</span><span class="w"> </span><span class="n">Client</span><span class="p">,</span><span class="w"> </span><span class="n">wait</span>
<span class="n">from</span><span class="w"> </span><span class="n">dask_cuda</span><span class="w"> </span><span class="n">import</span><span class="w"> </span><span class="n">LocalCUDACluster</span>
<span class="n">import</span><span class="w"> </span><span class="n">dask_cudf</span>

<span class="n">from</span><span class="w"> </span><span class="n">cuml.dask.ensemble</span><span class="w"> </span><span class="n">import</span><span class="w"> </span><span class="n">RandomForestClassifier</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">cumlDaskRF</span>
<span class="n">from</span><span class="w"> </span><span class="n">sklearn.ensemble</span><span class="w"> </span><span class="n">import</span><span class="w"> </span><span class="n">RandomForestClassifier</span><span class="w"> </span><span class="n">as</span><span class="w"> </span><span class="n">sklRF</span>


<span class="n">if</span><span class="w"> </span>__<span class="n">name__</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;__main__&quot;</span><span class="o">:</span>
<span class="w">    </span><span class="c1">### Start Dask cluster</span>
<span class="w">    </span><span class="c1"># This will use all GPUs on the local host by default</span>
<span class="w">    </span><span class="n">cluster</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">LocalCUDACluster</span><span class="p">(</span><span class="n">n_workers</span><span class="o">=</span><span class="m">2</span><span class="p">)</span>
<span class="w">    </span><span class="c1">#cluster = LocalCUDACluster(threads_per_worker=1)</span>
<span class="w">    </span><span class="n">c</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">Client</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span>

<span class="w">    </span><span class="c1"># Query the client for all connected workers</span>
<span class="w">    </span><span class="n">workers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c.has_what</span><span class="p">()</span><span class="nf">.keys</span><span class="p">()</span>
<span class="w">    </span><span class="n">n_workers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">len</span><span class="p">(</span><span class="n">workers</span><span class="p">)</span>
<span class="w">    </span><span class="n">n_streams</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">8</span><span class="w"> </span><span class="c1"># Performance optimization</span>

<span class="w">    </span><span class="c1">### Define Parameters</span>
<span class="w">    </span><span class="c1"># Data parameters</span>
<span class="w">    </span><span class="n">train_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">500000</span>
<span class="w">    </span><span class="n">test_size</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">1000</span>
<span class="w">    </span><span class="n">n_samples</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">train_size</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">test_size</span>
<span class="w">    </span><span class="n">n_features</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">20</span>

<span class="w">    </span><span class="c1"># Random Forest building parameters</span>
<span class="w">    </span><span class="n">max_depth</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">12</span>
<span class="w">    </span><span class="n">n_bins</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">16</span>
<span class="w">    </span><span class="n">n_trees</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="m">5000</span>

<span class="w">    </span><span class="c1">### Generate Data on host</span>
<span class="w">    </span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">datasets.make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="n">n_samples</span><span class="p">,</span><span class="w"> </span><span class="n">n_features</span><span class="o">=</span><span class="n">n_features</span><span class="p">,</span>
<span class="w">                                    </span><span class="n">n_clusters_per_class</span><span class="o">=</span><span class="m">1</span><span class="p">,</span><span class="w"> </span><span class="n">n_informative</span><span class="o">=</span><span class="nf">int</span><span class="p">(</span><span class="n">n_features</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="m">3</span><span class="p">),</span>
<span class="w">                                    </span><span class="n">random_state</span><span class="o">=</span><span class="m">123</span><span class="p">,</span><span class="w"> </span><span class="n">n_classes</span><span class="o">=</span><span class="m">5</span><span class="p">)</span>
<span class="w">    </span><span class="n">X</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">X.astype</span><span class="p">(</span><span class="n">np.float32</span><span class="p">)</span>
<span class="w">    </span><span class="n">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">y.astype</span><span class="p">(</span><span class="n">np.int32</span><span class="p">)</span>
<span class="w">    </span><span class="n">X_train</span><span class="p">,</span><span class="w"> </span><span class="n">X_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">,</span><span class="w"> </span><span class="n">y_test</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">model_selection.train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">,</span><span class="w"> </span><span class="n">test_size</span><span class="o">=</span><span class="n">test_size</span><span class="p">)</span>

<span class="w">    </span><span class="c1">### Distribute data to worker GPUs</span>
<span class="w">    </span><span class="n">n_partitions</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n_workers</span>

<span class="w">    </span><span class="n">def</span><span class="w"> </span><span class="nf">distribute</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">)</span><span class="o">:</span>
<span class="w">        </span><span class="c1"># First convert to cudf (with real data, you would likely load in cuDF format to start)</span>
<span class="w">        </span><span class="n">X_cudf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">cudf.DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="w">        </span><span class="n">y_cudf</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">cudf.Series</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="w">        </span><span class="c1"># Partition with Dask</span>
<span class="w">        </span><span class="c1"># In this case, each worker will train on 1/n_partitions fraction of the data</span>
<span class="w">        </span><span class="n">X_dask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">dask_cudf.from_cudf</span><span class="p">(</span><span class="n">X_cudf</span><span class="p">,</span><span class="w"> </span><span class="n">npartitions</span><span class="o">=</span><span class="n">n_partitions</span><span class="p">)</span>
<span class="w">        </span><span class="n">y_dask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">dask_cudf.from_cudf</span><span class="p">(</span><span class="n">y_cudf</span><span class="p">,</span><span class="w"> </span><span class="n">npartitions</span><span class="o">=</span><span class="n">n_partitions</span><span class="p">)</span>

<span class="w">        </span><span class="c1"># Persist to cache the data in active memory</span>
<span class="w">        </span><span class="n">X_dask</span><span class="p">,</span><span class="w"> </span><span class="n">y_dask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>\
<span class="w">        </span><span class="nf">dask_utils.persist_across_workers</span><span class="p">(</span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="p">[</span><span class="n">X_dask</span><span class="p">,</span><span class="w"> </span><span class="n">y_dask</span><span class="p">],</span><span class="w"> </span><span class="n">workers</span><span class="o">=</span><span class="n">workers</span><span class="p">)</span>

<span class="w">        </span><span class="n">return</span><span class="w"> </span><span class="n">X_dask</span><span class="p">,</span><span class="w"> </span><span class="n">y_dask</span>

<span class="w">    </span><span class="n">X_train_dask</span><span class="p">,</span><span class="w"> </span><span class="n">y_train_dask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">distribute</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="w"> </span><span class="n">y_train</span><span class="p">)</span>
<span class="w">    </span><span class="n">X_test_dask</span><span class="p">,</span><span class="w"> </span><span class="n">y_test_dask</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">distribute</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_test</span><span class="p">)</span>

<span class="w">    </span><span class="c1">### Build a scikit-learn model (single node)</span>
<span class="w">    </span><span class="c1"># Use all available CPU cores</span>
<span class="w">    </span><span class="c1">#skl_model = sklRF(max_depth=max_depth, n_estimators=n_trees, n_jobs=-1)</span>
<span class="w">    </span><span class="c1">#skl_model.fit(X_train.get(), y_train.get())</span>
<span class="w">    </span><span class="c1">#finish_time = time.perf_counter()</span>

<span class="w">    </span><span class="c1">### Predict</span>
<span class="w">    </span><span class="c1">#skl_y_pred = skl_model.predict(X_test.get())</span>
<span class="w">    </span><span class="c1">#print(&quot;SKLearn accuracy:  &quot;, accuracy_score(y_test, skl_y_pred))</span>

<span class="w">    </span><span class="c1">### Train the distributed cuML model</span>
<span class="w">    </span><span class="n">cuml_model</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">cumlDaskRF</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">,</span><span class="w"> </span><span class="n">n_estimators</span><span class="o">=</span><span class="n">n_trees</span><span class="p">,</span><span class="w"> </span><span class="n">n_bins</span><span class="o">=</span><span class="n">n_bins</span><span class="p">,</span><span class="w"> </span><span class="n">n_streams</span><span class="o">=</span><span class="n">n_streams</span><span class="p">)</span>
<span class="w">    </span><span class="nf">cuml_model.fit</span><span class="p">(</span><span class="n">X_train_dask</span><span class="p">,</span><span class="w"> </span><span class="n">y_train_dask</span><span class="p">)</span>
<span class="w">    </span><span class="nf">wait</span><span class="p">(</span><span class="n">cuml_model.rfs</span><span class="p">)</span><span class="w"> </span><span class="c1"># Allow asynchronous training tasks to finishfinish_time = time.perf_counter()</span>
<span class="w">    </span><span class="n">finish_time</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">time.perf_counter</span><span class="p">()</span>

<span class="w">    </span><span class="c1">### Predict</span>
<span class="w">    </span><span class="n">cuml_y_pred</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">cuml_model.predict</span><span class="p">(</span><span class="n">X_test_dask</span><span class="p">)</span><span class="nf">.compute</span><span class="p">()</span><span class="nf">.to_numpy</span><span class="p">()</span>
<span class="w">    </span><span class="nf">print</span><span class="p">(</span><span class="s">&quot;CuML accuracy:     &quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">cuml_y_pred</span><span class="p">))</span>
</code></pre></div>
<h3 id="track-the-gpu-usage">Track the GPU usage<a class="headerlink" href="#track-the-gpu-usage" title="Permanent link">&para;</a></h3>
<div class="highlight"><pre><span></span><code><span class="n">nvidia</span><span class="o">-</span><span class="n">smi</span><span class="w"> </span><span class="o">-</span><span class="n">l</span><span class="w"> </span><span class="m">5</span><span class="w"> </span><span class="c1"># Will update every 5 seconds</span>

<span class="c1"># Expected Output</span>
<span class="n">Mon</span><span class="w"> </span><span class="n">Aug</span><span class="w">  </span><span class="m">7</span><span class="w"> </span><span class="m">09</span><span class="o">:</span><span class="m">38</span><span class="o">:</span><span class="m">25</span><span class="w"> </span><span class="m">2023</span>
<span class="o">+-----------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="w"> </span><span class="n">Processes</span><span class="o">:</span><span class="w">                                                                  </span><span class="o">|</span>
<span class="o">|</span><span class="w">  </span><span class="n">GPU</span><span class="w">   </span><span class="n">GI</span><span class="w">   </span><span class="n">CI</span><span class="w">        </span><span class="n">PID</span><span class="w">   </span><span class="n">Type</span><span class="w">   </span><span class="n">Process</span><span class="w"> </span><span class="n">name</span><span class="w">                  </span><span class="n">GPU</span><span class="w"> </span><span class="n">Memory</span><span class="w"> </span><span class="o">|</span>
<span class="o">|</span><span class="w">        </span><span class="n">ID</span><span class="w">   </span><span class="n">ID</span><span class="w">                                                   </span><span class="n">Usage</span><span class="w">      </span><span class="o">|</span>
<span class="o">|=============================================================================|</span>
<span class="o">|</span><span class="w">    </span><span class="m">0</span><span class="w">   </span><span class="n">N</span><span class="o">/</span><span class="n">A</span><span class="w">  </span><span class="n">N</span><span class="o">/</span><span class="n">A</span><span class="w">      </span><span class="m">1011</span><span class="w">      </span><span class="n">G</span><span class="w">   </span><span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">xorg</span><span class="o">/</span><span class="n">Xorg</span><span class="w">                  </span><span class="m">4</span><span class="n">MiB</span><span class="w"> </span><span class="o">|</span>
<span class="o">|</span><span class="w">    </span><span class="m">0</span><span class="w">   </span><span class="n">N</span><span class="o">/</span><span class="n">A</span><span class="w">  </span><span class="n">N</span><span class="o">/</span><span class="n">A</span><span class="w">      </span><span class="m">2312</span><span class="w">      </span><span class="n">C</span><span class="w">   </span><span class="n">python</span><span class="w">                           </span><span class="m">1324</span><span class="n">MiB</span><span class="w"> </span><span class="o">|</span>
<span class="o">|</span><span class="w">    </span><span class="m">0</span><span class="w">   </span><span class="n">N</span><span class="o">/</span><span class="n">A</span><span class="w">  </span><span class="n">N</span><span class="o">/</span><span class="n">A</span><span class="w">      </span><span class="m">2381</span><span class="w">      </span><span class="n">C</span><span class="w">   </span><span class="n">...a3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">rapids</span><span class="o">/</span><span class="n">bin</span><span class="o">/</span><span class="n">python</span><span class="w">     </span><span class="m">1042</span><span class="n">MiB</span><span class="w"> </span><span class="o">|</span>
<span class="o">|</span><span class="w">    </span><span class="m">1</span><span class="w">   </span><span class="n">N</span><span class="o">/</span><span class="n">A</span><span class="w">  </span><span class="n">N</span><span class="o">/</span><span class="n">A</span><span class="w">      </span><span class="m">1011</span><span class="w">      </span><span class="n">G</span><span class="w">   </span><span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">xorg</span><span class="o">/</span><span class="n">Xorg</span><span class="w">                  </span><span class="m">4</span><span class="n">MiB</span><span class="w"> </span><span class="o">|</span>
<span class="o">|</span><span class="w">    </span><span class="m">1</span><span class="w">   </span><span class="n">N</span><span class="o">/</span><span class="n">A</span><span class="w">  </span><span class="n">N</span><span class="o">/</span><span class="n">A</span><span class="w">      </span><span class="m">2383</span><span class="w">      </span><span class="n">C</span><span class="w">   </span><span class="n">...a3</span><span class="o">/</span><span class="n">envs</span><span class="o">/</span><span class="n">rapids</span><span class="o">/</span><span class="n">bin</span><span class="o">/</span><span class="n">python</span><span class="w">     </span><span class="m">1042</span><span class="n">MiB</span><span class="w"> </span><span class="o">|</span>
<span class="o">+-----------------------------------------------------------------------------+</span>
<span class="n">Tue</span><span class="w"> </span><span class="n">Aug</span><span class="w"> </span><span class="m">29</span><span class="w"> </span><span class="m">11</span><span class="o">:</span><span class="m">04</span><span class="o">:</span><span class="m">31</span><span class="w"> </span><span class="m">2023</span>
<span class="o">+-----------------------------------------------------------------------------+</span>
<span class="o">|</span><span class="w"> </span><span class="n">NVIDIA</span><span class="o">-</span><span class="n">SMI</span><span class="w"> </span><span class="m">525.125</span><span class="n">.</span><span class="m">06</span><span class="w">   </span><span class="n">Driver</span><span class="w"> </span><span class="n">Version</span><span class="o">:</span><span class="w"> </span><span class="m">525.125</span><span class="n">.</span><span class="m">06</span><span class="w">   </span><span class="n">CUDA</span><span class="w"> </span><span class="n">Version</span><span class="o">:</span><span class="w"> </span><span class="m">12.0</span><span class="w">     </span><span class="o">|</span>
<span class="o">|-------------------------------+----------------------+----------------------+</span>
<span class="o">|</span><span class="w"> </span><span class="n">GPU</span><span class="w">  </span><span class="n">Name</span><span class="w">        </span><span class="n">Persistence</span><span class="o">-</span><span class="n">M</span><span class="o">|</span><span class="w"> </span><span class="n">Bus</span><span class="o">-</span><span class="n">Id</span><span class="w">        </span><span class="n">Disp.A</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">Volatile</span><span class="w"> </span><span class="n">Uncorr.</span><span class="w"> </span><span class="n">ECC</span><span class="w"> </span><span class="o">|</span>
<span class="o">|</span><span class="w"> </span><span class="n">Fan</span><span class="w">  </span><span class="n">Temp</span><span class="w">  </span><span class="n">Perf</span><span class="w">  </span><span class="n">Pwr</span><span class="o">:</span><span class="n">Usage</span><span class="o">/</span><span class="n">Cap</span><span class="o">|</span><span class="w">         </span><span class="n">Memory</span><span class="o">-</span><span class="n">Usage</span><span class="w"> </span><span class="o">|</span><span class="w"> </span><span class="n">GPU</span><span class="o">-</span><span class="n">Util</span><span class="w">  </span><span class="n">Compute</span><span class="w"> </span><span class="n">M.</span><span class="w"> </span><span class="o">|</span>
<span class="o">|</span><span class="w">                               </span><span class="o">|</span><span class="w">                      </span><span class="o">|</span><span class="w">               </span><span class="n">MIG</span><span class="w"> </span><span class="n">M.</span><span class="w"> </span><span class="o">|</span>
<span class="o">|===============================+======================+======================|</span>
<span class="o">|</span><span class="w">   </span><span class="m">0</span><span class="w">  </span><span class="n">Tesla</span><span class="w"> </span><span class="n">T4</span><span class="w">            </span><span class="n">Off</span><span class="w">  </span><span class="o">|</span><span class="w"> </span><span class="m">00000000</span><span class="o">:</span><span class="m">00</span><span class="o">:</span><span class="m">05.0</span><span class="w"> </span><span class="n">Off</span><span class="w"> </span><span class="o">|</span><span class="w">                    </span><span class="m">0</span><span class="w"> </span><span class="o">|</span>
<span class="o">|</span><span class="w"> </span><span class="n">N</span><span class="o">/</span><span class="n">A</span><span class="w">   </span><span class="m">38</span><span class="n">C</span><span class="w">    </span><span class="n">P0</span><span class="w">    </span><span class="m">49</span><span class="n">W</span><span class="w"> </span><span class="o">/</span><span class="w">  </span><span class="m">70</span><span class="n">W</span><span class="w"> </span><span class="o">|</span><span class="w">   </span><span class="m">2389</span><span class="n">MiB</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="m">15360</span><span class="n">MiB</span><span class="w"> </span><span class="o">|</span><span class="w">     </span><span class="m">93</span><span class="o">%      Default |</span>
<span class="o">|                               |                      |                  N/A |</span>
<span class="o">+-------------------------------+----------------------+----------------------+</span>
<span class="o">|   1  Tesla T4            Off  | 00000000:00:06.0 Off |                    0 |</span>
<span class="o">| N/A   36C    P0    53W /  70W |   1067MiB / 15360MiB |     93%</span><span class="w">      </span><span class="n">Default</span><span class="w"> </span><span class="o">|</span>
<span class="o">|</span><span class="w">                               </span><span class="o">|</span><span class="w">                      </span><span class="o">|</span><span class="w">                  </span><span class="n">N</span><span class="o">/</span><span class="n">A</span><span class="w"> </span><span class="o">|</span>
<span class="o">+-------------------------------+----------------------+----------------------+</span>
</code></pre></div>
<h3 id="transfer-results-and-conda-enviroment-local-machine-ssh-copy">Transfer Results and Conda enviroment local machine (SSH-Copy)<a class="headerlink" href="#transfer-results-and-conda-enviroment-local-machine-ssh-copy" title="Permanent link">&para;</a></h3>
<p>Open a second terminal (1st terminal is connected to the VM):</p>
<div class="highlight"><pre><span></span><code><span class="n">scp</span><span class="w"> </span><span class="o">-</span><span class="n">r</span><span class="w"> </span><span class="n">ucloud</span><span class="o">@</span><span class="n">IP_address_from_the_red_mark</span><span class="o">:/</span><span class="n">home</span><span class="o">/</span><span class="n">ucloud</span><span class="o">/</span><span class="n">folder</span><span class="w"> </span><span class="s">&quot;C:\path-to-folder&quot;</span>
</code></pre></div>





                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var tab,labels=set.querySelector(".tabbed-labels");for(tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs", "navigation.indexes", "toc.follow", "search.suggest", "search.higlight", "content.tabs.link", "content.code.annotation", "content.code.copy"], "search": "../../../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.b4d07000.min.js"></script>
      
    
  </body>
</html>