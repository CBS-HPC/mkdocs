{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"HPC &amp; Data Science Support at CBS","text":"<p>This is the GitHub repository for HPC &amp; Data Science Support at CBS. The team is dedicated to providing assistance and support to CBS researchers and students in their research utilizing the different HPC systems available at CBS. The repository contains various resources and information related to our services and activities.</p>"},{"location":"#activities","title":"Activities","text":"Tutorials &amp; User UtilitiesTeaching ActivitiesDevelopment of HPCDaily User SupportResearch Consultancy <p> The HPC &amp; Da Science Support team provides tutorials and user utilities to assist and support CBS researchers and students in their research utilizing the different HPC systems available at CBS. The tutorials and utilities covering various topics such as:</p> <ul> <li>Use cases for different HPC systems</li> <li>Efficient and secure data tranfer</li> <li>parallel computing</li> <li>environment management (e.g Conda)</li> </ul> <p>These tutorials offer step-by-step guidance, empowering users to effectively utilize HPC resources for their research. </p> <p> We conducts teaching activities through researcher and student webinars. Titles include \"High Performance Computing\", \"HPC &amp; Parallel Programming in R,\" and \"HPC &amp; Parallel Programming in Python\" with more in the pipeline.</p> <p>See \"Events\" section for more information.</p> <p>Upon receiving requests from course coordinators, we are also available to participate in teaching activities for courses at CBS.</p> <p> We are committed to the continuous development of HPC resources at CBS. This is both by ensuring that researchers have access to the right facilities, both short- and long-term, but also by providing a clear learning strategy for research to develop their HPC &amp; data science skillset.</p> <p> As Deic Front Office at CBS are we in charge off all communications with HPC system adminstrators (Back Office) and DeiC.</p> <p>Ideally, all user requests and troubleshooting should be send to the CBS Front Office(rdm@cbs.dk) as a Single Point of Contact (SPOC) where resulting tickets will be directed accordingly. </p> <p>This setup provides a better service to users and saves valuable time for Back Office technicians who can concentrate on highly technical issues.</p> <p> We provide consulting services to researchers and research projects, assisting them with their HPC requirements. Our support includes, but is not limited to, the following examples:</p> <ul> <li>HPC grant application guidance</li> <li>Assessing user needs for HPC resources</li> <li>Workflow and code optimization assistance</li> </ul> <p>By offering expert consultation, we help researchers identify and address their specific HPC needs, ensuring they can effectively utilize the available resources and optimize their workflows and code for maximum performance and efficiency.</p>"},{"location":"#data-science-links","title":"Data Science Links","text":"Reproducible Data ScienceOnline Learning <ul> <li>The Turing Way - Guide for Reproducible Research in Data Science </li> <li>Cookiecutter Data Science - Reproducible Project Structure</li> <li>Coderefinery - Introduction to version control with Git</li> <li>How to Create a Conda Environment Based on a YAML File: A Guide for Data Scientists</li> </ul> <ul> <li>High Performance Data Analytics in Python (Hosted by ENCCS) </li> <li>Kaggle.com: Online interactive data science courses</li> <li>Kaggle.com: Python</li> <li>Kaggle.com: Getting staRted in R: First Steps</li> <li>Datacarpentry - Introduction to Stata for Economics</li> </ul>"},{"location":"#hpcucloud-tutorials","title":"HPC/UCloud Tutorials","text":"GeneralRPythonSTATA / SAS / MatlabGPUsLarge Memory HPC <ul> <li>Getting Started with HPC (UCloud)</li> <li>Batch Processing on UCloud</li> <li>Rsync - Large data transfer to UCloud</li> <li>Synchronization to UCloud (Hosted by UCloud) </li> </ul> <ul> <li>Speed up your Linear Alegbra calculations by choosing the right BLAS/LAPACK Library</li> <li>Use Conda on UCloud to manage R-packages</li> <li>SLURM Clusters on UCloud</li> </ul> <ul> <li>Use Conda on UCloud to manage Python-libraries</li> <li>SLURM Clusters on UCloud</li> </ul> <p>STATA</p> <ul> <li>Run Stata on UCloud</li> <li>Install Stata on UCloud</li> <li>Run Stata in jupyter-notebooks</li> <li>Run Stata on Type 3 </li> </ul> <p>SAS</p> <ul> <li>Run SAS on UCloud</li> </ul> <p>Matlab</p> <ul> <li>Run Matlab on UCloud</li> </ul> <ul> <li>Which GPU to Choose?</li> <li>Access GPUs on UCloud</li> <li>GPU Libraries for Python and R</li> <li>Conda: for easy workflow deployment on AAU GPU VMs</li> <li>Run Python and R jupyter notebooks on AAU VMs</li> <li>Setting up jupyter-notebook with GPUs on AAU using Docker images (Hosted by RUC)</li> <li>Pytorch: Train your deep-learning models on UCloud GPUs</li> <li>Tensorflow: Train your deep-learning models on UCloud GPUs</li> <li>RAPIDS-cuML: Train your Scikit-learn models on UCloud GPUs</li> <li>RAPIDS-cuDF: How To Speed Up Pandas in Python By 150x</li> </ul> <ul> <li>Getting Started with large memory HPC (UCloud)</li> <li>Type 3 user guide (from SDU)</li> <li>Run Stata on Type 3 </li> <li>Use Conda to manage Jupyterlab environments on Type 3</li> </ul>"},{"location":"#hpc-operational-status","title":"HPC Operational Status","text":"<ul> <li>TYPE 1 (UCloud)</li> <li>TYPE 3 (Hippo)</li> <li>TYPE 5 (LUMI)</li> </ul> <p>Planned Maintenance</p> <ul> <li>04-12-23 - Planned upgrade of the DeiC Interactive HPC infrastructure</li> </ul>"},{"location":"contact/","title":"Contact","text":"<ul> <li>Research &amp; Data Management @ CBS (rdm@cbs.dk)</li> <li>Kristoffer Gulmark Poulsen (kgp.lib@cbs.dk)</li> <li>Lars Nondal (ln.lib@cbs.dk)</li> </ul>"},{"location":"events/","title":"Teaching Events","text":"For ResearchersFor StudentsFor All <p>\u00a0\u00a023-11-14 @ 14.00-15.00: - Train your ML/AI Model on GPUs - [Download Slides]</p> <p>\u00a0\u00a023-11-06 @ 13.00-14.00: - HPC &amp; Parallel Programming in R - [Download Slides]</p> <p>\u00a0\u00a023-11-02 @ 13.00-14.00: - HPC &amp; Parallel Programming in Python - [Download Slides]</p> <p>\u00a0\u00a023-10-31 @ 14.00-15.00: - High Performance Computing - [Download Slides]</p> <p></p> <p>\u00a0\u00a023-10-27 @ 13.00-14.00: - HPC &amp; Parallel Programming in Python - [Download Slides]</p> <p>\u00a0\u00a023-10-26 @ 13.00-14.00: - HPC &amp; Parallel Programming in R - [Download Slides]</p> <p>\u00a0\u00a023-10-23 @ 13.00-14.00: - High Performance Computing - [Download Slides]</p> <p></p> <ul> <li>23-09-11 -Nordic HPC Workshops - Parallel Computing and AI with MATLAB:  11, 18, 25 &amp; 26 September  </li> </ul>"},{"location":"getresources/","title":"Get Resources","text":""},{"location":"getresources/#national-resources","title":"National Resources","text":"<p>Need more Power - Free HPC-Cloud Computing Resources in 2024 -- Apply Before March 12!</p>"},{"location":"getresources/#local-resources","title":"Local Resources","text":"<p>Once a year CBS is awarded Local HPC ressources that can be freely distributed to our researchers and students. CBS primarily have Local Type 1 resources as the reflects our current user needs:</p>"},{"location":"getresources/#how-to-get-local-resources","title":"How to get Local Resources","text":"TYPE 1 (UCloud)TYPE 3 (Hippo)Other <ul> <li> <p>You apply from UCloud by sending a UCloud grant application. </p> </li> <li> <p>Information on machine type selection be found here. </p> </li> <li> <p>Otherwise please contact RDM Support.</p> </li> </ul> <p>Students</p> <ul> <li> <p>CBS students can only under very specific situation get access to Type 3 HPC. If this is of interrest you are welcome to contact RDM Support to discuss further.</p> </li> <li> <p>Please contact RDM Support if you would like to CBS to request Local resources to Type 3.</p> </li> </ul> <p>Staff</p> <ul> <li> <p>You apply from UCloud by sending a UCloud grant application. </p> </li> <li> <p>In 2023 CBS has a very limited Type 3 resource pool. Type 3 grant applications are therefore only granted after thorough evulation by the RDM Support.</p> </li> <li> <p>For more information please contact RDM Support.</p> </li> </ul> <p>Please contact RDM Support if you would like to CBS to request Local resources to Type 2 and 5.</p>"},{"location":"getresources/#sandbox-resources","title":"Sandbox Resources","text":"<p>CBS researchers wanting to test out HPC systems Type 2 to 5 can gain acess to sandbox ressources by contacting RDM Support. Find more information here.</p>"},{"location":"getresources/#grant-applications","title":"Grant Applications","text":"<p>Find an overview of currently open application rounds below. Please contact RDM Support as soon as possible if you consider applying as we can aid in the application process.</p> <ul> <li> <p>TYPE 1 to 3: Researcher can apply for the bi-annual application round for the national HPC resources. </p> </li> <li> <p>TYPE 5 &amp; other international HPC systems: Researcher can apply for resources at LUMI and other international HPC facilities. </p> </li> </ul>"},{"location":"getresources/#current-calls","title":"Current Calls","text":"<ul> <li>DeiC - Call H1-2024 Call for applications for access to the e- resources - (Deadline: September 5th, 2023)</li> </ul>"},{"location":"getresources/#external-links","title":"External Links","text":"<ul> <li>Apply for national HPC resources</li> <li>Acknowledge the use of national HPC </li> <li>The EuroCC Knowledge Pool (Hosted by DeiC)</li> </ul>"},{"location":"hpc/","title":"HPC Facilites","text":"<ul> <li>Type 1 \u2013 Interactive HPC (UCloud)</li> <li>Type 3 \u2013 Large Memory HPC (Hippo)</li> <li>National HPC Facilities (DeiC)</li> <li>WRDS - Wharton Research Data Services</li> <li>Nationalt Genom Center HPC (Danish Statistics Data)</li> </ul>"},{"location":"news/","title":"News","text":"<ul> <li>23-10-25 - Whisper large language model from OpenAI for Transcription of audio files (UCloud)</li> <li>23-08-24 - Larger GPU machine available for UCloud</li> <li>23-07-24 - CodeRefinery workshop September 19-21 and 26-28, 2023</li> <li>23-07-14 - DeiC - Call H1-2024 Call for applications for access to the e- resources</li> <li>23-06-27 - Interactive HPC lives up to highest international standards with ISO 27001</li> <li>23-06-12 - New way to use SSH for accessing apps on Interactive HPC</li> <li>23-05-31 - UCloud Maintenance notice - 27/06/2023</li> <li>23-04-26 - UCloud scheduled maintenance between 8:00-10:00 on Wednesday 26/04/2023.</li> <li>23-04-12 - New milestone as DeiC Interactive HPC reaches 6,000 users</li> <li>23-03-17 - The cost of success \u2013 user overload on DeiC Interactive HPC</li> <li>23-03-15 - Launch of the DeiC Integration Portal</li> </ul>"},{"location":"tut_docs/","title":"Tutorials &amp; Documentation","text":""},{"location":"tut_docs/#cbs-tutorials","title":"CBS Tutorials","text":"Type 1: CPUType 1: GPU <ul> <li>Getting Started with HPC (UCloud)</li> <li>Speed up your Linear Algebra calculations by choosing the right BLAS/LAPACK Library</li> <li>Using Conda on UCloud to manage R-packages and Python-libraries</li> <li>SLURM Clusters on UCloud</li> <li>Batch Processing on UCloud</li> <li>Rsync - Large data transfer to UCloud</li> </ul> <ul> <li>Access GPUs on UCloud</li> <li>Conda: for easy workflow deployment on AAU GPU VMs</li> <li>Run Python and R jupyter notebooks on AAU VMs</li> <li>Pytorch: Train your deep-learning models on UCloud GPUs</li> <li>Tensorflow: Train your deep-learning models on UCloud GPUs</li> <li>RAPIDS-cuML: Train your Scikit-learn models on UCloud GPUs</li> <li>RAPIDS-cuDF: How To Speed Up Pandas in Python By 150x</li> </ul>"},{"location":"tut_docs/#type-1-ucloud","title":"TYPE 1 (UCloud)","text":"SDUAAU <ul> <li>Manage Files and Folders (Hosted by UCloud)</li> <li>Manage Applications (Hosted by UCloud)</li> <li>Manage Workspaces (Hosted by UCloud)</li> <li>Use Cases (Hosted by UCloud)</li> <li>Webinars (Hosted by UCloud)</li> <li>UCloud Documentation (Hosted by UCloud)</li> <li>Synchronization to UCloud (Hosted by UCloud)</li> <li>Quick guide on running JupyterLab on UCloud (Hosted by RUC) </li> </ul> <ul> <li>Setting up jupyter-notebook with GPUs on AAU (Hosted by RUC)</li> </ul>"},{"location":"tut_docs/#type-2-throughput","title":"TYPE 2 (Throughput)","text":"<ul> <li>Computerome 2.0 - Documentation</li> <li>GenomeDK - Documentation</li> <li>Sophia - Documentation</li> </ul>"},{"location":"tut_docs/#type-3-hippo","title":"TYPE 3 (Hippo)","text":"<ul> <li>User Guide (Hosted by UCloud)</li> </ul>"},{"location":"tut_docs/#type-5-lumi","title":"TYPE 5 (LUMI)","text":"<ul> <li>Cotainr (Hosted by DeiC)</li> </ul>"},{"location":"tut_docs/#general-hpc-documentation","title":"General HPC Documentation","text":"<ul> <li>ENCCS Lessons</li> <li>Virtual SLURM Learning (Hosted by DeiC)</li> </ul>"},{"location":"tut_docs/#python","title":"Python","text":"<ul> <li>High Performance Data Analytics in Python (Hosted by ENCCS) </li> </ul>"},{"location":"tut_docs/#other-links","title":"Other Links","text":"<ul> <li>DeiC HPC GitHub</li> <li>RUC HPC</li> <li>Code Refinery</li> </ul>"},{"location":"HPC_Facilities/DeiC/","title":"National HPC Facilities","text":"<p>This page provides an overview of the national HPC facilities (Content is provided by DeiC). </p>"},{"location":"HPC_Facilities/DeiC/#type-1-ucloud","title":"TYPE 1 (UCloud)","text":"<p>The type 1 system is mainly focused on interactive computing and easy access for users. The system is made of the YouGene cluster hosted at SDU. CBS staff and students can access the cluster resources via UCloud. </p> <p>Get for Type 1 resources here.</p> <p>More information is found here.</p>"},{"location":"HPC_Facilities/DeiC/#type-2-throughput-hpc","title":"TYPE 2 (Throughput HPC)","text":"<p>Three Type 2 HPC systems are available (Computerome 2.0,GenomeDK and Sophia). This type of HPC system typically has a large number of cores which can be a mix between cost-effective and calculation-efficient units. Type 2 also has the ability to handle large amounts of data and its main focus is on high-throughput performance. </p> <p>Get for Type 2 resources here.</p> <p>More information is found here:</p> <p>Computerome 2.0  \u00a0\u00a0 | \u00a0\u00a0 GenomeDK \u00a0\u00a0 | \u00a0\u00a0 Sophia</p>"},{"location":"HPC_Facilities/DeiC/#type-3-hippo","title":"TYPE 3 (Hippo)","text":"<p>This is a large memory HPC. This type of HPC system focuses on problem solving, with a structure that cannot be easily or efficiently distributed between many computer nodes. This is a type of system that is characterized by typically relatively few cores with access to a large globally addressable memory area. </p> <p>Type 3 is hosted and maintained at SDU. For the cluster specs check here. </p> <p>User guide can be found here. </p> <p>Get for Type 3 resources here.</p> <p>More information is found here.</p>"},{"location":"HPC_Facilities/DeiC/#type-5-lumi","title":"TYPE 5 (LUMI)","text":"<p>Type 5 is the European pre-exascale supercomputer LUMI. LUMI is an abbreviation for \"Large Unified Modern Infrastructure\", and will be located in CSC's data center in Kajaani, Finland. LUMI is one of three pre-exascale supercomputers to be build as part of the European EuroHPC project.</p> <p>LUMI Capability HPC provides a similar setup to DeiC Throughput HPC but with increased possibilities by virtue of state-of-the-art hardware. Specifically the interconnections between compute nodes is designed to minimize latency thereby addressing the issue of communication induced latency in distributed-memory programs running on separate nodes. Additionally the user can obtain access to large amounts of disk space also with low-latency interconnects. In this way Capability HPC enables computations that are prohibitive with DeiC Throughput HPC due to communication latency. </p> <p>Get for Type 5 resources here.</p> <p>More information is found here.</p>"},{"location":"HPC_Facilities/GrantApp/","title":"Applying for ressources in 6 Simple Steps","text":"<p>If you have any further questions you are welcome to contact RDM Support.</p>"},{"location":"HPC_Facilities/GrantApp/#step-1-select-apply-for-resources-on-the-ucloud-frontpage","title":"Step 1: Select \"Apply for resources\" on the UCloud frontpage","text":""},{"location":"HPC_Facilities/GrantApp/#step-2-select-apply-for-new-project-instead","title":"Step 2: Select \"Apply for new project instead\"","text":""},{"location":"HPC_Facilities/GrantApp/#step-3-provide-a-project-title-and-choose-hpc-type-1-or-3","title":"Step 3: Provide a project title and choose HPC type (1 or 3)","text":""},{"location":"HPC_Facilities/GrantApp/#step-4-select-storage-amount-and-machine-type","title":"Step 4: Select storage amount and machine type.","text":"<p>The requested resources should either be given in DKK or Core Hours</p>"},{"location":"HPC_Facilities/GrantApp/#cpu-machines-deic-interactive-hpc-sdu-red-circle","title":"CPU Machines / DeiC Interactive HPC (SDU)  (Red Circle)","text":"<ul> <li>u1-standard in DKK</li> </ul>"},{"location":"HPC_Facilities/GrantApp/#gpu-machines-deic-interactive-hpc-aau-blue-circles","title":"GPU Machines / DeiC Interactive HPC (AAU) (Blue Circles)","text":"<ul> <li> <p>uc-t4\" (GPU) in DKK</p> </li> <li> <p>uc-t4-h\" (GPU) in Core Hours</p> </li> <li> <p>uc-A100-h\" (GPU) in Core Hours</p> </li> <li> <p>uc-A40-h\" (GPU) in Core Hours</p> </li> <li> <p>uc-A10-h\" (GPU) in Core Hours</p> </li> </ul> <p></p>"},{"location":"HPC_Facilities/GrantApp/#step-5-project-description-software-license","title":"Step 5: project description &amp; software license","text":"<p>Provide a meaningfull project description &amp; select SAS or STATA License (if needed). </p>"},{"location":"HPC_Facilities/GrantApp/#step-6-press-submit-application","title":"Step 6: Press \"Submit application\"","text":"<p>Now the application will be evaluated by the CBS front office at first given opportunity. The application will either be accepted otherwise you will be contacted (CBS mail).</p> <p></p>"},{"location":"HPC_Facilities/Hippo/","title":"Type 3 \u2013 Large Memory HPC (Hippo)","text":"<p>This type of HPC system focuses on problem solving, with a structure that cannot be easily or efficiently distributed between many computer nodes. This is a type of system that is characterized by typically relatively few cores with access to a large globally addressable memory area. Type 3 is hosted and maintained at SDU. </p> <p>The DeiC Large Memory HPC system is a system consisting of large memory nodes (between 1 and 4 TB RAM per node).</p> <p>System specifications can be found here.</p>"},{"location":"HPC_Facilities/Hippo/#get-started","title":"Get started","text":"<p>Large Memory HPC (Hippo) is integrated with UCloud which providing an easy-to-use interface.</p> <p>The UCloud integration provides three base applications RStudio, JupyterLab and Slurm. See apps.</p> <ul> <li> <p>RStudio and JupyterLab facilites interactive jobs on a single Type3 node for a range of popular programming languages.</p> </li> <li> <p>Slurm provides batch job processing across multiple Type 3 nodes.</p> </li> </ul> <p>To get resources read here.</p> <p>Start by reading the following Type 3 tutorials:</p> <ul> <li>Type 3 user guide (from SDU)</li> <li>Run Stata on Type 3 </li> <li>Use Conda to manage Jupyterlab environments on Type 3</li> </ul>"},{"location":"HPC_Facilities/Hippo/#user-support","title":"User Support","text":"<p>All UCloud support should go through the RDM Support. If problems cannot be solved locally the CBS Front office will take contact to the UCloud system adminstrators (Back Office). </p> <p>This setup provides a better service to users and saves valuable time for Back Office technicians who can concentrate on highly technical issues.</p>"},{"location":"HPC_Facilities/License/","title":"Add License to STATA and SAS application","text":"<p>If you have any further questions you are welcome to contact RDM Support.</p>"},{"location":"HPC_Facilities/License/#add-local-license","title":"Add Local License","text":""},{"location":"HPC_Facilities/License/#step-1-upload-local-stata-lic-file-or-sas-txt-file-license-to-ucloud","title":"Step 1: Upload local STATA (.lic file) or SAS (.txt file) license to UCloud","text":""},{"location":"HPC_Facilities/License/#step-2-select-the-license-file-lic-or-txt-while-setting-up-ucloud-job","title":"Step 2: Select the license file (.lic or .txt) while setting up UCloud Job","text":""},{"location":"HPC_Facilities/License/#add-server-license","title":"Add Server License","text":""},{"location":"HPC_Facilities/License/#step-1-apply-for-server-license-through-ucloud-grant-application","title":"Step 1: Apply for Server License through UCloud Grant Application","text":""},{"location":"HPC_Facilities/License/#step-2-activate-license-sas-94-license-shown-as-example","title":"Step 2: Activate License (SAS 9.4 license shown as example)","text":""},{"location":"HPC_Facilities/License/#step-3-select-server-license-while-setting-up-ucloud-job","title":"Step 3: Select server license while setting up UCloud Job","text":""},{"location":"HPC_Facilities/MachineType/","title":"Type 1 \u2013 Interactive HPC (UCloud)","text":"<p>The easiest-to-use HPC service is DeiC Interactive HPC (Type 1) also known as UCloud. This service is provided by the Danish universities SDU and AAU.</p> SDUAAU <p>SDU provides CPU based containerized applications such as MATLAB, STATA, RStudio, and JupyterLab through a graphical user interface (GUI), in the same way as you would on your laptop. See all apps. </p> <p>u1-standard</p> <p>The following machines are available:</p> <p></p> <p>The specification of the largest node (u1-standard-64) are summarized below:</p> <p>Dell PowerEdge C6420</p> <p>CPU:    64 (32 virtual cores) 2x Intel Xeon Gold 6130 16-Core @ 2.10GHz</p> <p>RAM: 384 GB  DDR 4-2666</p> <p>Price: 5,49 DKK/hour</p> <p>Description: The full node consists of 2x Intel(R) Xeon(R) Gold 6130 CPU@2.10 GHz, 32 virtual cores/CPU, and 384 GB of memory.</p> <p>AAU provides primary GPU based virtual machines. Access is obtained through terminal and SSH. It is possible to set up interactive enviroments such as JupyterLab.</p> <p>Four different machine types based on different Nvidia GPUs (T4, A10 , A40 and A100) with different application purposes. </p> Nvidia T4Nvidia A10Nvidia A40Nvidia A100Specification Comparisons <ul> <li>AI Inference: The T4 is optimized for AI inference workloads, making it suitable for applications like image and speech recognition, natural language processing, and recommendation systems in data centers.</li> </ul> <p>Nvidia T4 is avaliable on the following machines:</p> <p></p> <p></p> <ul> <li>Data Center Workloads: The A10 offers a balance of compute power and memory, making it versatile for various data center tasks, including virtualization, cloud computing, and database acceleration.</li> </ul> <p>Nvidia A10 is avaliable on the following machines:</p> <p></p> <ul> <li>High-Performance Computing (HPC): The A40 is designed for HPC applications, such as scientific simulations, climate modeling, and molecular dynamics, where high computational power is essential.</li> </ul> <p>Nvidia A40 is avaliable on the following machines:</p> <p></p> <ul> <li>Deep Learning and AI Research: The A100 excels in deep learning training and AI research, enabling faster model training for tasks like image recognition, natural language understanding, and autonomous driving.</li> <li>High-Performance Computing (HPC): It's also used in HPC environments for tasks like molecular dynamics simulations, quantum chemistry, and climate modeling, thanks to its exceptional computational capabilities.</li> </ul> <p>Nvidia A100 is avaliable on the following machines:</p> <p></p> <p>Their specifications are summarized in a table below.</p> GPU Architecture CUDA Cores Tensor Cores Memory FP16 (Half) TFLOPS FP32 (Float) TFLOPS FP64 (Double) GFLOPS Data Sheet Nvidia T4 Turing 2,560 320 16 GB GDDR6 65.1 8.1 254.4 T4 Nvidia A10 Ampere 6,144 384 24 GB GDDR6 31.2 31.2 976.3 A10 Nvidia A40 Ampere 10,240 320 48 GB GDDR6 37.4 37.4 0.59 A40 Nvidia A100 Ampere 6,912 432 80 GB HBM2 78.0 19.5 9700 A100 <ul> <li> <p>CUDA cores are the general-purpose processing units in a GPU that can perform computations with standard floating-point precision, such as single-precision (32-bit) or double-precision (64-bit).</p> </li> <li> <p>Tensor Cores are optimized to trade off precision for speed and can significantly accelerate deep learning training and inference.</p> </li> <li> <p>A more detailed description can be found here.</p> </li> </ul>"},{"location":"HPC_Facilities/NGC/","title":"Nationalt Genom Center HPC (Danish Statistics Data)","text":"<p>It is possible to access and process data from Danish Statistics through the Nationalt Genom Center HPC. This service is not funded by CBS. See pricing list.</p> <p>A techinal guide is found here.</p> <p>The linked information is only avaliable in danish.</p> <p>For further information or support please contact RDM Support.</p>"},{"location":"HPC_Facilities/Overview/","title":"Overview","text":"<ul> <li>Type 1 \u2013 Interactive HPC (UCloud)</li> <li>National HPC Facilities (DeiC)</li> <li>WRDS - Wharton Research Data Services</li> <li>Nationalt Genom Center HPC (Danish Statistics Data)</li> <li>HPC Operational Status</li> </ul>"},{"location":"HPC_Facilities/UCloud/","title":"Type 1 \u2013 Interactive HPC (UCloud)","text":"<p>The easiest-to-use HPC service is DeiC Interactive HPC (Type 1) also known as UCloud. This service is provided by the Danish universities SDU and AAU.</p> <p>SDU provides CPU based containerized applications such as MATLAB, STATA, RStudio, and JupyterLab through a graphical user interface (GUI), in the same way as they would on your laptop. See all apps. </p> <p>AAU provides primary GPU based virtual machines. Access is obtained through terminal and SSH. It is possible to set up interactive enviroments such as JupyterLab. </p> <p>System specifications can be found here.</p>"},{"location":"HPC_Facilities/UCloud/#login-on-ucloud","title":"Login on UCloud","text":"<p>You can login on to UCloud using WAYF (Where Are You From). Press here to login.</p> <ul> <li>Select Copenhagen Business School as your affiliate institution on the login page. </li> <li>Sign in using your CBS mail account</li> </ul> <p>Upon the first login it is necessary to approve the SDU eScience terms of service. Afterwards, the user is redirected to the UCloud user interface.</p> <p>Note: After login the user can activate two factor authentication by clicking on the avatar icon in the top-right corner of the home screen.</p>"},{"location":"HPC_Facilities/UCloud/#getting-started","title":"Getting started","text":"<p>All new users in UCloud are awarded a \"My Workspace\" with 1000 DKK of computing (CPU only) resources to the \"DeiC Interactive HPC (SDU)\", as well as 50 GB remote storage. You can use these resources to get acquainted with the system, run test jobs, etc. </p> <p>The largest machine (64 cores &amp; 384 GB memory) cost 5.49kr/Hour. So the free 1000 DKK will give you access to approx. 182 hours of inital run time.</p> <p>For additional resources see here.</p> <p>Start by watching the following UCloud tutorials:</p> <ul> <li>Manage Files and Folders</li> <li>Manage Applications</li> <li>Manage Workspaces</li> <li>Use Cases</li> <li>Webinars</li> <li>UCloud Documentation</li> </ul> <p>More Tutorials and Documentation can be found here</p>"},{"location":"HPC_Facilities/UCloud/#user-support","title":"User Support","text":"<p>All UCloud support should go through the RDM Support. If problems cannot be solved locally the CBS Front office will take contact to the UCloud system adminstrators (Back Office). </p> <p>This setup provides a better service to users and saves valuable time for Back Office technicians who can concentrate on highly technical issues.</p>"},{"location":"HPC_Facilities/UCloud/#collaboration","title":"Collaboration","text":"<p> International Collaborators</p> <p>International researchers need a \"visiting researcher premission\"(g\u00e6steforskeradgang) to CBS to gain access to UCloud. One can be obtained by contacting CBS HR (hr@cbs.dk).</p> <p>Once this is in place CBS HPC support will contact the UCloud Research Support Team and provide the below shown information. </p> <ul> <li> <p>Full name:</p> </li> <li> <p>Occupation:</p> </li> <li> <p>Organisation (University):</p> </li> <li> <p>Email (University):</p> </li> </ul> <p>Subsequently, the UCloud Research Support Team will contact the researcher to verify their identity through a video meeting. A valid ID is needed. </p>"},{"location":"HPC_Facilities/UCloud/#license-software","title":"License Software","text":"<p>There are several types of licensed software that can be run on UCloud. </p> MATLABSTATASAS &amp; SAS Studio <p>  A Matlab server license is needed in order to run the application on UCloud. Once can be acquired through CBS IT help desk at own expense.</p> <ul> <li> <p>Matlab UCloud Application</p> </li> <li> <p>UCloud Matlab Documentation</p> </li> <li> <p>UCloud video tutorial </p> <ul> <li>Matlab walkthrough starts at 16:00 minutes into the video. </li> <li>Shows how activate Matlab with a personal license.</li> </ul> </li> </ul> <p> Users can either upload their own personal STATA license (.lic file) to UCloud or apply for one through a UCloud Grant Application.</p> <p>After being granted the license the user should perform the following steps. </p> <ul> <li> <p>STATA UCloud Application</p> </li> <li> <p>UCloud STATA Documentation</p> </li> </ul> <p> Users can either upload their own personal SAS license (.txt file) or apply for one through a UCloud Grant Application.</p> <p>After being granted the license the user should perform the following steps. </p> <ul> <li> <p>SAS UCloud Application</p> </li> <li> <p>UCloud SAS Documentation</p> </li> </ul>"},{"location":"HPC_Facilities/WRDS/","title":"WRDS - Wharton Research Data Services","text":"<p>WRDS- Wharton Research Data Services provides access to financial data, accounting figures as well as banking and management information. CBS students and staff must register to get access. </p> <p>More information can be found here.</p> <p>For further support lease contact RDM Support.</p>"},{"location":"HPC_Facilities/WRDS/#accessing-wrds-databases","title":"Accessing WRDS databases:","text":""},{"location":"HPC_Facilities/WRDS/#local-pc-ucloud","title":"Local PC &amp; UCloud","text":"<ul> <li>Python</li> <li>R</li> <li>Matlab</li> <li>SAS</li> <li>STATA</li> <li>UCloud Templates/Scripts </li> </ul>"},{"location":"HPC_Facilities/WRDS/#wrds-cloud","title":"WRDS Cloud","text":"<p>WRDS Cloud is a HPC service with the possibility to process the data avaliable on WRDS. WRDS Cloud is only acessable for CBS staff and researchers.</p>"},{"location":"HPC_Facilities/WRDS/#available-software","title":"Available Software","text":"<p>The WRDS Cloud provides the following software:</p> <ul> <li>SAS 9.4</li> <li>R 3.5</li> <li>Python 3.6 and 2.7</li> <li>Stata 15 (requires special subscription agreement with StataCorp)</li> </ul> <p>In addition, it further supports remote access from:</p> <ul> <li>MATLAB 2016a +</li> <li>Native PostgreSQL clients</li> <li>ODBC- or JDBC-compliant clients</li> </ul>"},{"location":"HPC_Facilities/WRDS/#wrds-cloud-documentation","title":"WRDS Cloud Documentation","text":"<ul> <li>Introduction to the WRDS Cloud</li> <li>Using SSH to Connect to the WRDS Cloud </li> </ul>"},{"location":"HPC_Facilities/status/","title":"HPC Operational Status","text":"<ul> <li>Type 1 (UCloud)</li> <li>Type 3 (Hippo)</li> <li>Type 5 (LUMI)</li> </ul>"},{"location":"Tutorial_Docs/BLAS/","title":"UCloud Tutorial: Speed up your Linear Alegbra calculations by choosing the right BLAS/LAPACK Library","text":"<p>When it comes to numerical computations and linear algebra in the R programming language, the BLAS (Basic Linear Algebra Subprograms) and LAPACK (Linear Algebra Package) libraries play crucial roles. These libraries provide a collection of efficient and optimized routines for various linear algebra operations, such as matrix multiplication, solving linear systems, eigenvalue computations, and more.</p> <p>BLAS, the Basic Linear Algebra Subprograms, is a standard interface specification for low-level linear algebra operations. It defines a set of routines that perform basic vector and matrix operations efficiently. The BLAS routines are highly optimized and implemented in highly efficient machine code to take advantage of the specific hardware architecture. R relies on the BLAS library for fundamental linear algebra operations, providing performance improvements for numerical computations.</p> <p>LAPACK, the Linear Algebra Package, builds upon the BLAS library and provides higher-level routines for solving more complex linear algebra problems. LAPACK offers a comprehensive set of algorithms for solving systems of linear equations, eigenvalue problems, least-squares problems, and singular value decompositions. These routines are widely used in various scientific and engineering applications.</p>"},{"location":"Tutorial_Docs/BLAS/#r","title":"R","text":"<ul> <li>Speed up your Linear Alegbra calculations 78 times by choosing the right RStudio version on UCloud.</li> </ul>"},{"location":"Tutorial_Docs/BatchMode/","title":"UCloud Tutorial: Batch Processing on UCloud","text":"<p>Running non-interactive script in \"batch mode\" can help overcome the UCloud capacity issues as jobs can be started any time and then executed whenever the systems resources permits.  </p> <p>Many applications already have a \"Batch Processing\" UCloud functionality:</p> <ul> <li>Batch Processing</li> <li>RStudio</li> <li>JupyterLab</li> <li>Matlab</li> <li>PyTorch</li> <li>Tensorflow</li> <li>Spark Cluster</li> <li>Terminal/SLURM Cluster</li> </ul> <p>Application that currently does not have this UCloud functionality (e.g. Stata) can instead run batch mode computations using the terminal app. See the following tutorials:</p> <ul> <li>Stata</li> </ul>"},{"location":"Tutorial_Docs/Conda/","title":"Conda on UCloud","text":"<p>Package, dependency and environment management for any language\u2014Python, R and more.</p> <p>The following links provides step-by-step guides on how to install and use Conda for R and Python on a range of different UCloud applications (R Studio, VScode, JupyterLab and Terminal App).</p> <p>Using a Conda environement elimnates the need for re-installing all the needed packages/libraries when starting a UCloud Job.</p> <p>This approach is also highly useful when running multi-node Slurm Clusters. </p> <ul> <li> <p>R</p> </li> <li> <p>Python</p> </li> </ul> <p>Further documentation can be found on UCloud:</p> <ul> <li>Conda on UCloud </li> </ul>"},{"location":"Tutorial_Docs/VMs/","title":"Access GPUs on UCloud","text":"<ul> <li> <p>GPUs are accessible on UCloud through virtual machines (VMs) hosted by AAU. </p> </li> <li> <p>GPU resources can  be obtained through a UCloud grant application.</p> </li> <li> <p>Information of the different GPU systems can be found here.</p> </li> </ul>"},{"location":"Tutorial_Docs/VMs/#tutorials","title":"Tutorials","text":"<ul> <li> <p>How to Generate SSH key</p> </li> <li> <p>Access at data transfer to AAU VMs using SSH</p> </li> </ul>"}]}