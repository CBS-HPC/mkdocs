{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "493460ea",
   "metadata": {},
   "source": [
    "## Example using Ray \n",
    "\n",
    "In terminal run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38f27c1",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "python slurm-launch.py --script slurm-template_ray.sh --exp-name SlurmTest --command \"python /work/SLURM_scripts/SklearnRay.py\" --num-nodes 3\n",
    "\n",
    "# Output\n",
    "\n",
    "Starting to submit job!\n",
    "Job submitted! Script file is at: <SlurmTest_0425-1208.sh>. Log file is at: <SlurmTest_0425-1208.log>\n",
    "Submitted batch job 2\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e1879fa",
   "metadata": {},
   "source": [
    "### Open extra Terminal for three Nodes \n",
    "![](SLURM3.PNG)\n",
    "\n",
    "### Run \"top\" command is used to show the Linux processes.\n",
    "![](SLURM4.PNG)\n",
    "\n",
    "### Observed that the work is disbrubted across all three nodes. \n",
    "This may look different for different backends (e.g. Dask). It should be noted that in this example on 8 core nodes were used. Full nodes (64 cores) will generate alot more processes.\n",
    "\n",
    "![](SLURM5.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "622735cb",
   "metadata": {},
   "source": [
    "## Output files\n",
    "\n",
    "### The autogenerated SLURM script (SlurmTest_0425-1208.sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8380c1a7",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "# shellcheck disable=SC2206\n",
    "# THIS FILE IS GENERATED BY AUTOMATION SCRIPT! PLEASE REFER TO ORIGINAL SCRIPT!\n",
    "# THIS FILE IS MODIFIED AUTOMATICALLY FROM TEMPLATE AND SHOULD BE RUNNABLE!\n",
    "\n",
    "#SBATCH --job-name=SlurmTest_0425-1208\n",
    "#SBATCH --output=SlurmTest_0425-1208.log\n",
    "\n",
    "### This script works for any number of nodes, Ray will find and manage all resources\n",
    "#SBATCH --nodes=3\n",
    "#SBATCH --exclusive\n",
    "### Give all resources to a single Ray task, ray can manage the resources internally\n",
    "#SBATCH --ntasks-per-node=1\n",
    "##SBATCH --gpus-per-task=${NUM_GPUS_PER_NODE} #De-activated by KGP 230317\n",
    "\n",
    "# Load modules or your own conda environment here\n",
    "# module load pytorch/v1.4.0-gpu\n",
    "# conda activate ${CONDA_ENV}\n",
    "\n",
    "\n",
    "# ===== DO NOT CHANGE THINGS HERE UNLESS YOU KNOW WHAT YOU ARE DOING =====\n",
    "\n",
    "echo $SLURM_JOB_NODELIST\n",
    "\n",
    "nodes=$(scontrol show hostnames \"$SLURM_JOB_NODELIST\") # Getting the node names\n",
    "\n",
    "nodes_array=($nodes)\n",
    "node_1=${nodes_array[0]}\n",
    "ip=$(srun --nodes=1 --ntasks=1 -w \"$node_1\" hostname --ip-address) # making redis-address\n",
    "\n",
    "# if we detect a space character in the head node IP, we'll\n",
    "# convert it to an ipv4 address. This step is optional.\n",
    "if [[ \"$ip\" == *\" \"* ]]; then\n",
    "  IFS=' ' read -ra ADDR <<< \"$ip\"\n",
    "  if [[ ${#ADDR[0]} -gt 16 ]]; then\n",
    "    ip=${ADDR[1]}\n",
    "  else\n",
    "    ip=${ADDR[0]}\n",
    "  fi\n",
    "  echo \"IPV6 address detected. We split the IPV4 address as $ip\"\n",
    "fi\n",
    "\n",
    "port=6379\n",
    "ip_head=$ip:$port\n",
    "export ip_head\n",
    "echo \"IP Head: $ip_head\"\n",
    "\n",
    "echo \"STARTING HEAD at $node_1\"\n",
    "srun --nodes=1 --ntasks=1 -w \"$node_1\" ray start --head --node-ip-address=\"$ip\" --port=$port --block &\n",
    "sleep 30\n",
    "\n",
    "#worker_num=$((SLURM_JOB_NUM_NODES - 1)) #number of nodes other than the head node\n",
    "#export NB_WORKERS=$((${SLURM_JOB_NUM_NODES-1})) #number of nodes other than the head node\n",
    "#echo ${NB_WORKERS}\n",
    "\n",
    "export NB_WORKERS=$((SLURM_JOB_NUM_NODES - 1)) #number of nodes other than the head node\n",
    "echo \"STARTING ${NB_WORKERS} WORKERS\"\n",
    "for ((i = 1; i <= NB_WORKERS; i++)); do\n",
    "  node_i=${nodes_array[$i]}\n",
    "  echo \"STARTING WORKER $i at $node_i\"\n",
    "  srun --nodes=1 --ntasks=1 -w \"$node_i\" ray start --address \"$ip_head\" --block &\n",
    "  sleep 5\n",
    "done\n",
    "\n",
    "# ===== Call your code below =====\n",
    "echo \"RUNNING CODE: python /work/data/SklearnRay.py\"\n",
    "python /work/data/SklearnRay.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c2d3c135",
   "metadata": {},
   "source": [
    "### Autogenerated log file (SlurmTest_0425-1208.log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7676f5",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "node[0-2]\n",
    "IPV6 address detected. We split the IPV4 address as 10.42.47.86\n",
    "IP Head: 10.42.47.86:6379\n",
    "STARTING HEAD at node0\n",
    "2023-04-25 12:08:40,054 WARNING utils.py:652 -- Ray currently does not support initializing Raywith fractional cpus. Your num_cpus will be truncated from 7.5 to 7.\n",
    "STARTING 2 WORKERS\n",
    "STARTING WORKER 1 at node1\n",
    "2023-04-25 12:08:38,026 INFO usage_lib.py:461 -- Usage stats collection is enabled by default without user confirmation because this terminal is detected to be non-interactive. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.\n",
    "2023-04-25 12:08:38,026 INFO scripts.py:710 -- Local node IP: 10.42.47.86\n",
    "2023-04-25 12:08:41,222 SUCC scripts.py:747 -- --------------------\n",
    "2023-04-25 12:08:41,222 SUCC scripts.py:748 -- Ray runtime started.\n",
    "2023-04-25 12:08:41,223 SUCC scripts.py:749 -- --------------------\n",
    "2023-04-25 12:08:41,223 INFO scripts.py:751 -- Next steps\n",
    "2023-04-25 12:08:41,223 INFO scripts.py:752 -- To connect to this Ray runtime from another node, run\n",
    "2023-04-25 12:08:41,223 INFO scripts.py:755 --   ray start --address='10.42.47.86:6379'\n",
    "2023-04-25 12:08:41,223 INFO scripts.py:771 -- Alternatively, use the following Python code:\n",
    "2023-04-25 12:08:41,223 INFO scripts.py:773 -- import ray\n",
    "2023-04-25 12:08:41,223 INFO scripts.py:777 -- ray.init(address='auto', _node_ip_address='10.42.47.86')\n",
    "2023-04-25 12:08:41,223 INFO scripts.py:790 -- To see the status of the cluster, use\n",
    "2023-04-25 12:08:41,223 INFO scripts.py:791 --   ray status\n",
    "2023-04-25 12:08:41,223 INFO scripts.py:801 -- If connection fails, check your firewall settings and network configuration.\n",
    "2023-04-25 12:08:41,224 INFO scripts.py:809 -- To terminate the Ray runtime, run\n",
    "2023-04-25 12:08:41,224 INFO scripts.py:810 --   ray stop\n",
    "2023-04-25 12:08:41,224 INFO scripts.py:891 -- --block\n",
    "2023-04-25 12:08:41,224 INFO scripts.py:892 -- This command will now block forever until terminated by a signal.\n",
    "2023-04-25 12:08:41,224 INFO scripts.py:895 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.\n",
    "STARTING WORKER 2 at node2\n",
    "2023-04-25 12:08:48,882 WARNING utils.py:652 -- Ray currently does not support initializing Raywith fractional cpus. Your num_cpus will be truncated from 7.5 to 7.\n",
    "[2023-04-25 12:08:48,933 I 2244 2244] global_state_accessor.cc:356: This node has an IP address of 10.42.28.36, while we can not find the matched Raylet address. This maybe come from when you connect the Ray cluster with a different IP address or connect a container.\n",
    "2023-04-25 12:08:48,859 INFO scripts.py:866 -- Local node IP: 10.42.28.36\n",
    "2023-04-25 12:08:48,935 SUCC scripts.py:878 -- --------------------\n",
    "2023-04-25 12:08:48,935 SUCC scripts.py:879 -- Ray runtime started.\n",
    "2023-04-25 12:08:48,935 SUCC scripts.py:880 -- --------------------\n",
    "2023-04-25 12:08:48,935 INFO scripts.py:882 -- To terminate the Ray runtime, run\n",
    "2023-04-25 12:08:48,935 INFO scripts.py:883 --   ray stop\n",
    "2023-04-25 12:08:48,935 INFO scripts.py:891 -- --block\n",
    "2023-04-25 12:08:48,935 INFO scripts.py:892 -- This command will now block forever until terminated by a signal.\n",
    "2023-04-25 12:08:48,935 INFO scripts.py:895 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.\n",
    "RUNNING CODE: python /work/data/SklearnRay.py\n",
    "2023-04-25 12:08:54,215 WARNING utils.py:652 -- Ray currently does not support initializing Raywith fractional cpus. Your num_cpus will be truncated from 7.5 to 7.\n",
    "[2023-04-25 12:08:54,271 I 956 956] global_state_accessor.cc:356: This node has an IP address of 10.42.34.213, while we can not find the matched Raylet address. This maybe come from when you connect the Ray cluster with a different IP address or connect a container.\n",
    "2023-04-25 12:08:54,135 INFO scripts.py:866 -- Local node IP: 10.42.34.213\n",
    "2023-04-25 12:08:54,274 SUCC scripts.py:878 -- --------------------\n",
    "2023-04-25 12:08:54,275 SUCC scripts.py:879 -- Ray runtime started.\n",
    "2023-04-25 12:08:54,275 SUCC scripts.py:880 -- --------------------\n",
    "2023-04-25 12:08:54,275 INFO scripts.py:882 -- To terminate the Ray runtime, run\n",
    "2023-04-25 12:08:54,275 INFO scripts.py:883 --   ray stop\n",
    "2023-04-25 12:08:54,275 INFO scripts.py:891 -- --block\n",
    "2023-04-25 12:08:54,275 INFO scripts.py:892 -- This command will now block forever until terminated by a signal.\n",
    "2023-04-25 12:08:54,275 INFO scripts.py:895 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.\n",
    "2023-04-25 12:09:24,758 INFO worker.py:1364 -- Connecting to existing Ray cluster at address: 10.42.47.86:6379...\n",
    "2023-04-25 12:09:24,775 INFO worker.py:1553 -- Connected to Ray cluster.\n",
    "2023-04-25 12:09:25,073 WARNING pool.py:604 -- The 'context' argument is not supported using ray. Please refer to the documentation for how to control ray initialization.\n",
    "Fitting 10 folds for each of 500 candidates, totalling 5000 fits\n",
    "209.00055767036974\n",
    "srun: Job step aborted: Waiting up to 32 seconds for job step to finish.\n",
    "srun: Job step aborted: Waiting up to 32 seconds for job step to finish.\n",
    "srun: Job step aborted: Waiting up to 32 seconds for job step to finish.\n",
    "slurmstepd-node2: error: *** STEP 2.3 ON node2 CANCELLED AT 2023-04-25T12:12:54 ***\n",
    "slurmstepd-node0: error: *** STEP 2.1 ON node0 CANCELLED AT 2023-04-25T12:12:54 ***\n",
    "slurmstepd-node1: error: *** STEP 2.2 ON node1 CANCELLED AT 2023-04-25T12:12:54 ***\n",
    "srun: error: node2: task 0: Exited with exit code 1\n",
    "srun: error: node1: task 0: Exited with exit code 1\n",
    "srun: error: node0: task 0: Exited with exit code 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7fc92",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
